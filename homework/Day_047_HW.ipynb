{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "了解如何使用 Sklearn 中的 hyper-parameter search 找出最佳的超參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業\n",
    "請使用不同的資料集，並使用 hyper-parameter search 的方式，看能不能找出最佳的超參數組合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 讀取資料集\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分訓練集/測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "def findBestGradientBoosting():\n",
    "    # Choose some parameter combinations to try\n",
    "    param_grid = {'n_estimators': [80 , 100, 200, 300, 400, 500], \n",
    "                  'max_depth': [2, 3, 5], \n",
    "                  'learning_rate': [0.005, 0.01,0.05,0.07, 0.08]\n",
    "                 }\n",
    "\n",
    "    # 建立模型\n",
    "    clf = GradientBoostingRegressor(random_state=7)\n",
    "    # Run the grid search\n",
    "    grid_obj = GridSearchCV(estimator = clf,param_grid = param_grid, verbose=1)\n",
    "    grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "    # 印出最佳結果與最佳參數\n",
    "    print(\"Best Accuracy: %f using %s\" % (grid_obj.best_score_, grid_obj.best_params_))\n",
    "    return grid_obj.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 90 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.439773 using {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 100}\n",
      "2576.170487333019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 270 out of 270 | elapsed:   23.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the best algorithm to the data. \n",
    "clf = findBestGradientBoosting()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 MSE: 3003.847495722414\n",
      "Fold 2 MSE: 2843.4525994325427\n",
      "Fold 3 MSE: 3121.2051978314103\n",
      "Fold 4 MSE: 3089.0134644335926\n",
      "Fold 5 MSE: 3202.848514933675\n",
      "Fold 6 MSE: 3350.42994842942\n",
      "Fold 7 MSE: 3720.8663159375046\n",
      "Fold 8 MSE: 2737.3783645960057\n",
      "Fold 9 MSE: 4593.443031213643\n",
      "Fold 10 MSE: 2171.6417544611463\n",
      "Mean MSE: 3183.4126686991353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "def run_kfold(clf):\n",
    "    kf = KFold(n_splits=10)\n",
    "    outcomes = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(diabetes.data):\n",
    "        fold += 1\n",
    "        X_train, X_test = diabetes.data[train_index], diabetes.data[test_index]\n",
    "        y_train, y_test = diabetes.target[train_index], diabetes.target[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = mean_squared_error(y_test, predictions)\n",
    "        outcomes.append(accuracy)\n",
    "        print(\"Fold {0} MSE: {1}\".format(fold, accuracy))     \n",
    "    mean_outcome = np.mean(outcomes)\n",
    "    print(\"Mean MSE: {0}\".format(mean_outcome)) \n",
    "\n",
    "run_kfold(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
